------------------------------------------------------------------------------------------------------------------------------------
Reviewer A:

The paper tries to improve [9] by using static analysis to identify possible paths in PUTs. Authors also use multiple fitness functions for each test path instead of only one in [9]. In particular, the fitness function is computed from function in Algorithm 4. Table 6 shows some better experimental results compared to [9].

However, the paper is not well-written. English writing is not easy to read and understand in many places. E.g. 
- the last sentence in Abstract has two main verbs.
- .. as Figure 1 following
- .. statistical analysis -> static 
- .. logic structures of program simplify..
- .. number of days of February of the not leap year
- .. theses formulas
- .. list of fitness function
- .. the set ... are
- .. it can be see that 
- ...
----------
--> Base on your comment, I revised all my English mistakes
----------

Algorithm 2 is problematic: 
2: "G = a graph by linking all blocks in B to each other" so it means a graph with all possible edges, between any two nodes.
3: update graph by replacing P with G. What is the initial value for graph? I assume it is empty, so replacing P with G does not make sense. 
----------
--> Before performing this algorithm, graph is initialized as a global variable and contains only one vertex representing for the given program P.	
I also added this explanation into our paper.	
----------

In Section 5 the authors compare only four programs, while in [9] there are eight. So it does not convince me the approach is really better. 
----------
--> Because our proposed approach is to build a fitness function for each test path of a given program under test(PUT), so that for remainder 4 PUTs
(calDay, cal, remainder, bessj) in the benchmark of Mao, we also get good results such as that of Mao [9](Success rate = 100% and Average coverage = 100%).
By the way, I added experimental analysis for reminder 4 PUT into my papers.
----------

The paper has not shown significant and clear contributions so I tend to reject the paper. 
------------------------------------------------------------------------------------------------------------------------------------
Reviewer B:

The paper presents a method of generating test data based on Particle Swarm Optimization (PSO). The method consists of many steps: generating CFG, generating test paths (based on [28]) and generating test data based on PSO by basing the idea in Mao's work in [9].

The most important contribution in this work is to define one fitness function for each test path instead of one fitness function for all test paths compared to [9]. The authors show that their work is better than Mao's work in [9].

However, in my opinion, the paper has some following issues:

- The experimentation is quite simple, the method should be applied to more complicated programs. They did not apply to other programs in the benchmark in [9] to see if they get the same effectiveness. In addition, we doubt that the experimental rates obtained were 100%, so the method is excellent!
----------
--> Because our proposed approach is to build a fitness function for each test path of a given program under test(PUT), so that for remainder 4 PUTs
(calDay, cal, remainder, bessj) in the benchmark of Mao, we also get good results such as that of Mao [9](Success rate = 100% and Average coverage = 100%).
By the way, I added experimental analysis for reminder 4 PUT into my papers.

Because our proposed approach is to build a fitness function for each test path of a given program under test(PUT),  and PSO uses these fitness functions
to generate suitable test data, so that we always can generate test data to cover all branches of the PUT.
However, this proposal also has some limitations that I wrote in the Conclusion section.
----------

- This work may have better results in terms of coverage, but the paper did not mention the other factors, such as memory, execution time...
----------
--> I added environment and platform information which was used to perform our proposed approach into the Experimental analysis section.
----------

- There are many English errors and presentation problems.
----------
--> I checked and revised all English mistakes in our paper
----------

- The second paragraph of the Conclusion section was completely copied from [9}. This would not be acceptable!
----------
--> I revised furture work paragraph of the Conclusion section.					
----------

In overall, the paper is clearly written, but the contribution is a bit limited.
------------------------------------------------------------------------------------------------------------------------------------